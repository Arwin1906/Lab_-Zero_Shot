{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Task_1.synthetic_dataset import SyntheticDataset\n",
    "from Arwin.model.trainer import Trainer\n",
    "from Arwin.model.deeponet import *\n",
    "from Task_1.utils import collate_fn_fixed, collate_fn\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 256\n",
    "data_train_path = 'Arwin/dataset/training_dataset.pkl'\n",
    "data_test_path = 'Arwin/dataset/testing_dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling Functions from Beta Distribution 1/6 with a=1, b=2: 100%|██████████| 16666/16666 [00:59<00:00, 280.37it/s]\n",
      "Sampling Functions from Beta Distribution 2/6 with a=1, b=5: 100%|██████████| 16666/16666 [00:58<00:00, 282.48it/s]\n",
      "Sampling Functions from Beta Distribution 3/6 with a=2, b=1: 100%|██████████| 16666/16666 [00:55<00:00, 298.07it/s]\n",
      "Sampling Functions from Beta Distribution 4/6 with a=2, b=5: 100%|██████████| 16666/16666 [00:56<00:00, 293.68it/s]\n",
      "Sampling Functions from Beta Distribution 5/6 with a=5, b=1: 100%|██████████| 16666/16666 [00:56<00:00, 295.04it/s]\n",
      "Sampling Functions from Beta Distribution 6/6 with a=5, b=2: 100%|██████████| 16670/16670 [00:56<00:00, 297.41it/s]\n",
      "Generating Observations: 100%|██████████| 100000/100000 [00:07<00:00, 13887.16it/s]\n",
      "Sampling Functions from Beta Distribution 1/6 with a=1, b=2: 100%|██████████| 166/166 [00:00<00:00, 294.36it/s]\n",
      "Sampling Functions from Beta Distribution 2/6 with a=1, b=5: 100%|██████████| 166/166 [00:00<00:00, 252.48it/s]\n",
      "Sampling Functions from Beta Distribution 3/6 with a=2, b=1: 100%|██████████| 166/166 [00:00<00:00, 352.99it/s]\n",
      "Sampling Functions from Beta Distribution 4/6 with a=2, b=5: 100%|██████████| 166/166 [00:00<00:00, 339.08it/s]\n",
      "Sampling Functions from Beta Distribution 5/6 with a=5, b=1: 100%|██████████| 166/166 [00:00<00:00, 249.66it/s]\n",
      "Sampling Functions from Beta Distribution 6/6 with a=5, b=2: 100%|██████████| 170/170 [00:00<00:00, 290.52it/s]\n",
      "Generating Observations: 100%|██████████| 1000/1000 [00:00<00:00, 11606.58it/s]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SyntheticDataset(100000, 128, padding=False, verbose=True)\n",
    "valid_dataset = SyntheticDataset(1000, 128, padding=False, verbose=True, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_train_path, 'wb') as f:\n",
    "#     pickle.dump(train_dataset, f)\n",
    "# with open(data_test_path, 'wb') as f:\n",
    "#     pickle.dump(valid_dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pickle.load(open(data_train_path, 'rb'))\n",
    "valid_dataset = pickle.load(open(data_test_path, 'rb'))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_fixed)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TBOARD_LOGS = os.path.join(\"./Arwin\", \"tboard_logs\", \"IM1_test_old_data\")\n",
    "if not os.path.exists(TBOARD_LOGS):\n",
    "    os.makedirs(TBOARD_LOGS)\n",
    "shutil.rmtree(TBOARD_LOGS) \n",
    "writer = SummaryWriter(TBOARD_LOGS)\n",
    "\n",
    "indicator_dim = 128\n",
    "\n",
    "deeponet = DeepONet(indicator_dim=indicator_dim, d_model=128, heads=2, p=128).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "trainer = Trainer(model=deeponet, criterion=criterion, train_loader=train_loader, valid_loader=validation_loader, modelname=\"IM1_test_old_data\", epochs=1, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 1: Loss=4.60431:   0%|          | 0/391 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 0: Loss=3.8943673968315125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 51: Loss=0.95691:  13%|█▎        | 50/391 [00:58<06:14,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 50: Loss=0.9449968338012695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 101: Loss=0.52609:  26%|██▌       | 100/391 [01:54<05:21,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 100: Loss=0.48773299902677536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 151: Loss=0.42879:  38%|███▊      | 150/391 [02:51<04:26,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 150: Loss=0.4040740244090557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 201: Loss=0.23386:  51%|█████     | 200/391 [03:47<03:28,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 200: Loss=0.2207348570227623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 251: Loss=0.23658:  64%|██████▍   | 250/391 [04:44<02:36,  1.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 250: Loss=0.20880890358239412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 301: Loss=0.20008:  77%|███████▋  | 300/391 [05:41<01:40,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 300: Loss=0.20040403213351965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 351: Loss=0.23587:  90%|████████▉ | 350/391 [06:38<00:44,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 350: Loss=0.19371278584003448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 391: Loss=0.22018: 100%|█████████▉| 390/391 [07:24<00:01,  1.14s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
