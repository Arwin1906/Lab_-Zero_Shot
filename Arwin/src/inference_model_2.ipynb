{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pickle\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from Arwin.dataset.synthetic_dataset import SyntheticDataset\n",
    "from Arwin.dataset.windowed_dataset import WindowedDataset\n",
    "from Arwin.model.trainer_Im2 import TrainerIM2 as Trainer\n",
    "from Arwin.model.deeponet import DeepONet\n",
    "from Arwin.model.embedding_forecaster import EmbeddingForcaster\n",
    "from Arwin.src.utils import *\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "BATCH_SIZE = 128\n",
    "data_train_path = 'Arwin/dataset/training_dataset.pkl'\n",
    "data_test_path = 'Arwin/dataset/testing_dataset.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = pickle.load(open(data_train_path, 'rb'))\n",
    "valid_dataset = pickle.load(open(data_test_path, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Prepare dataset \"\"\"\n",
    "training_dataset_windows = WindowedDataset(training_dataset.functions, training_dataset.observations, training_dataset.masks, shuffle=True)\n",
    "valid_dataset_windows = WindowedDataset(valid_dataset.functions, valid_dataset.observations, valid_dataset.masks, eval=True, shuffle=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset_windows, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn_windows)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset_windows, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_forward(deeponet, y, t, eval_grid_points, mask):\n",
    "    # Generate the fine grid points batch dynamically for the current batch size\n",
    "    batch_size = y.shape[0]\n",
    "    fine_grid_points_batch = eval_grid_points.unsqueeze(0).expand(batch_size, -1)\n",
    "\n",
    "    # Mask the input data\n",
    "    y = y.unsqueeze(-1) * mask.unsqueeze(-1)\n",
    "    t = t.unsqueeze(-1) * mask.unsqueeze(-1)\n",
    "    t_sample =  fine_grid_points_batch.unsqueeze(-1)\n",
    "    # Branch and Trunk Embedding\n",
    "    branch_embedding_y = deeponet.branch_embedding_y(y)\n",
    "    branch_embedding_t = deeponet.branch_embedding_t(t)\n",
    "    trunk_encoder_input = deeponet.trunk_embedding_t(t_sample)\n",
    "\n",
    "    # generate mask for the transformer encoder\n",
    "    mask_enc = torch.where(mask == 1, False, True)\n",
    "\n",
    "    # Transformer Encoder for the Branch Network\n",
    "    branch_encoder_input = deeponet.embedding_act(branch_embedding_y + branch_embedding_t)\n",
    "    branch_encoder_output = deeponet.branch_encoder(branch_encoder_input, src_key_padding_mask=mask_enc)\n",
    "\n",
    "    # Mask the output of the transformer encoder\n",
    "    branch_encoder_output = branch_encoder_output * mask.unsqueeze(-1)\n",
    "    \"\"\" Modifications to the original DeepONet \"\"\"\n",
    "    # Attention-based summary\n",
    "    H = branch_encoder_output  # Shape: [batch_size, 128, d_model]\n",
    "    q = deeponet.query.unsqueeze(0).expand(batch_size, -1, -1)  # Shape: [batch_size, 1, d_model]\n",
    "\n",
    "    # Multihead attention: query (q), keys/values (H)\n",
    "    h_b, _ = deeponet.summary_attention(q, H, H, key_padding_mask=mask_enc)  # h_b: [batch_size, 1, d_model]\n",
    "    h_b = h_b.squeeze(1)  # Flatten to [batch_size, d_model]\n",
    "\n",
    "    return h_b\n",
    "    \"\"\" -------------------------------------- \"\"\"\n",
    "    branch_output = self.branch_mlp(h_b) \n",
    "    trunk_output = self.trunk_mlp(trunk_encoder_input)\n",
    "\n",
    "    \"\"\" Modifications to the original DeepONet \"\"\"\n",
    "    # Expand branch_output to match the sequence length of trunk_output\n",
    "    branch_output_expanded = branch_output.unsqueeze(1).expand(-1, trunk_output.shape[1], -1)  # [batch_size, d_model, p]\n",
    "\n",
    "    # Concatenate branch_output with trunk_output along the feature dimension\n",
    "    combined_input = torch.cat((branch_output_expanded, trunk_output), dim=-1)  # [batch_size, d_model, 2 * p]\n",
    "\n",
    "    # Flatten the batch and sequence dimensions to apply combined_mlp in one step\n",
    "    combined_input_flattened = combined_input.view(-1, combined_input.shape[-1])  # [batch_size * d_model, 2 * p]\n",
    "\n",
    "    # Pass through combined_mlp\n",
    "    mlp_output = self.combined_mlp(combined_input_flattened)  # [batch_size * d_model, 1]\n",
    "\n",
    "    # Reshape back to the original structure\n",
    "    combined_out = mlp_output.view(branch_output.shape[0], trunk_output.shape[1])  # [batch_size, d_model]\n",
    "\n",
    "    \"\"\" -------------------------------------- \"\"\"\n",
    "        \n",
    "    return combined_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (512x9 and 6x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m indices_to_keep \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(scales\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m5\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m  \u001b[38;5;66;03m# Create a mask to keep elements\u001b[39;00m\n\u001b[1;32m     48\u001b[0m scales_filtered \u001b[38;5;241m=\u001b[39m scales[indices_to_keep]  \u001b[38;5;66;03m# Filter scales to keep only elements that are not every 5th element\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m scales_out \u001b[38;5;241m=\u001b[39m \u001b[43mscales_mlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscales_filtered\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(scales_out\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     53\u001b[0m h_b \u001b[38;5;241m=\u001b[39m new_forward(deeponet, y_observations, t_observations, eval_grid_points, masks)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:216\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (512x9 and 6x128)"
     ]
    }
   ],
   "source": [
    "d_model = 128\n",
    "p = 128\n",
    "\n",
    "deeponet = DeepONet(indicator_dim=128, d_model=d_model, heads=2, p=p).to(device)\n",
    "scales_mlp = nn.Sequential(\n",
    "                nn.Linear(6 ,d_model),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.LeakyReLU(),\n",
    "                nn.Linear(d_model, d_model),\n",
    "                nn.LeakyReLU(),\n",
    ")\n",
    "scales_mlp = scales_mlp.to(device)\n",
    "\n",
    "forecast_encoder = nn.TransformerEncoder(\n",
    "    nn.TransformerEncoderLayer(d_model=d_model*2, nhead=8, batch_first=True), num_layers=4, enable_nested_tensor=False\n",
    ").to(device)\n",
    "\n",
    "query = nn.Parameter(torch.randn(1, 2*d_model))\n",
    "summary_attention = nn.MultiheadAttention(embed_dim=2*d_model, num_heads=8, batch_first=True).to(device)\n",
    "\n",
    "# Linear projection layer to adjust output dimension\n",
    "projection_layer = nn.Linear(2 * d_model, d_model).to(device)\n",
    "\n",
    "\n",
    "deeponet.eval()\n",
    "scales_mlp.eval()\n",
    "forecast_encoder.eval()\n",
    "summary_attention.eval()\n",
    "projection_layer.eval()\n",
    "\n",
    "for y_value_windows, (y_observation_windows, t_observation_windows), mask_windows, scale_windows in train_loader:\n",
    "    y_value_windows = y_value_windows.to(device)\n",
    "    y_observation_windows = y_observation_windows.to(device)\n",
    "    t_observation_windows = t_observation_windows.to(device)\n",
    "    mask_windows = mask_windows.to(device)\n",
    "    eval_grid_points = torch.linspace(0, 1, 128, device=device)\n",
    "\n",
    "    # Flatten Windows to be of shape (batch_size * num_windows, window_size)\n",
    "    y_values = y_value_windows.view(-1, y_value_windows.size(2))\n",
    "    y_observations = y_observation_windows.view(-1, y_observation_windows.size(2))\n",
    "    t_observations = t_observation_windows.view(-1, t_observation_windows.size(2))\n",
    "    masks = mask_windows.view(-1, mask_windows.size(2))\n",
    "    scales = torch.stack([tensor.to(device) for sublist in scale_windows for tensor in sublist])\n",
    "\n",
    "    # Select indices that are not every 5th element\n",
    "    indices_to_keep = torch.arange(scales.size(0)) % 5 != 0  # Create a mask to keep elements\n",
    "    scales_filtered = scales[indices_to_keep]  # Filter scales to keep only elements that are not every 5th element\n",
    "\n",
    "    scales_out = scales_mlp(scales_filtered)\n",
    "    print(scales_out.shape)\n",
    "\n",
    "    h_b = new_forward(deeponet, y_observations, t_observations, eval_grid_points, masks)\n",
    "    print(h_b.shape)\n",
    "\n",
    "    concat = torch.cat((h_b[indices_to_keep], scales_out), dim=1)\n",
    "    print(concat.shape)\n",
    "\n",
    "    forecast_out = forecast_encoder(concat)\n",
    "    print(forecast_out.shape)\n",
    "\n",
    "    forecast_out = forecast_out.view(128, -1, d_model*2)\n",
    "    print(forecast_out.shape)\n",
    "    print(forecast_out[0]) # 4 embeddings of size 2*d_model for each window of the first batch element\n",
    "\n",
    "    # mask should not be required since it was already applied to get h_b and scales do not require masking\n",
    "    mask_enc = torch.where(masks == 1, False, True)\n",
    "    print(mask_enc.shape)\n",
    "    \n",
    "    q = query.unsqueeze(0).expand(BATCH_SIZE, -1, -1).to(device)  # Shape: [batch_size, 1, 2*d_model]\n",
    "    u_b, _ = summary_attention(q, forecast_out, forecast_out)  # u_b: [batch_size, 1, 2*d_model]\n",
    "    print(u_b.shape)\n",
    "\n",
    "    u_b = projection_layer(u_b.squeeze(1))\n",
    "    print(u_b.shape)\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeponet = DeepONet(indicator_dim=128, d_model=128, heads=2, p=128).to(device)\n",
    "optim = {\"model\": torch.optim.AdamW(deeponet.parameters(), lr=4.6e-4)}\n",
    "\n",
    "deeponet, optimizers, epoch, stats = load_model(deeponet, optim, \"./Arwin/checkpoints/New_Im1/checkpoint_epoch_3900_New_Im1.pth\")\n",
    "\n",
    "TBOARD_LOGS = os.path.join(\"./Arwin\", \"tboard_logs\", \"Im2\")\n",
    "if not os.path.exists(TBOARD_LOGS):\n",
    "    os.makedirs(TBOARD_LOGS)\n",
    "shutil.rmtree(TBOARD_LOGS) \n",
    "writer = SummaryWriter(TBOARD_LOGS)\n",
    "\n",
    "indicator_dim = 128\n",
    "\n",
    "forecaster = EmbeddingForcaster(d_model=128).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "trainer = Trainer(deeponet=deeponet, model=forecaster, criterion=criterion, train_loader=train_loader, valid_loader=valid_loader, modelname=\"Im2\", epochs=5, writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 1: Loss=0.87433:   0%|          | 0/782 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 0: Loss=0.7729404451800328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 101: Loss=0.08433:  13%|█▎        | 100/782 [01:26<08:50,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 100: Loss=0.07623382993772918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 201: Loss=0.07542:  26%|██▌       | 200/782 [02:52<07:29,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 200: Loss=0.07223113056491404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 301: Loss=0.06541:  38%|███▊      | 300/782 [04:18<06:23,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 300: Loss=0.06751365002756025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 401: Loss=0.06448:  51%|█████     | 400/782 [05:45<04:50,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 400: Loss=0.06332823057092872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 501: Loss=0.06337:  64%|██████▍   | 500/782 [07:11<03:45,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 500: Loss=0.06374388801700928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 601: Loss=0.05514:  77%|███████▋  | 600/782 [08:37<02:19,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 600: Loss=0.05937538244852833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 701: Loss=0.05803:  90%|████████▉ | 700/782 [10:03<01:05,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 700: Loss=0.058248331295508965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 0 Iter 782: Loss=0.06362: 100%|██████████| 782/782 [11:14<00:00,  1.16it/s]\n",
      "Ep 1 Iter 19: Loss=0.06178:   2%|▏         | 18/782 [00:14<10:09,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 800: Loss=0.05692511183374068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 119: Loss=0.06196:  15%|█▌        | 118/782 [01:40<08:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 900: Loss=0.05461935092713319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 219: Loss=0.05725:  28%|██▊       | 218/782 [03:06<07:10,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1000: Loss=0.053900719200279196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 319: Loss=0.0466:  41%|████      | 318/782 [04:33<06:06,  1.27it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1100: Loss=0.050893309653974046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 419: Loss=0.04942:  53%|█████▎    | 418/782 [05:59<04:48,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1200: Loss=0.048560019144240546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 519: Loss=0.0525:  66%|██████▌   | 518/782 [07:26<03:31,  1.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1300: Loss=0.048180603951800106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 619: Loss=0.0528:  79%|███████▉  | 618/782 [08:52<02:07,  1.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1400: Loss=0.04809432425627522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 719: Loss=0.04628:  92%|█████████▏| 718/782 [10:18<00:48,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1500: Loss=0.04833162597873632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 1 Iter 782: Loss=0.04344: 100%|██████████| 782/782 [11:15<00:00,  1.16it/s]\n",
      "Ep 2 Iter 37: Loss=0.04425:   5%|▍         | 36/782 [00:29<09:49,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1600: Loss=0.04682091251015663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 137: Loss=0.04409:  17%|█▋        | 136/782 [01:55<08:13,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1700: Loss=0.045416006854936186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 237: Loss=0.03946:  30%|███       | 236/782 [03:22<07:13,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1800: Loss=0.04514013537589241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 337: Loss=0.05037:  43%|████▎     | 336/782 [04:48<05:40,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 1900: Loss=0.04442735513051351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 437: Loss=0.03877:  56%|█████▌    | 436/782 [06:14<04:24,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2000: Loss=0.043549499529249525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 537: Loss=0.03786:  69%|██████▊   | 536/782 [07:40<03:11,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2100: Loss=0.043499155225707034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 637: Loss=0.04435:  81%|████████▏ | 636/782 [09:05<01:54,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2200: Loss=0.04384953572469599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 737: Loss=0.04131:  94%|█████████▍| 736/782 [10:31<00:35,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2300: Loss=0.043176799209094514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2 Iter 782: Loss=0.03592: 100%|██████████| 782/782 [11:14<00:00,  1.16it/s]\n",
      "Ep 3 Iter 55: Loss=0.04322:   7%|▋         | 54/782 [00:42<09:19,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2400: Loss=0.04330571886955523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 155: Loss=0.0431:  20%|█▉        | 154/782 [02:08<08:17,  1.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2500: Loss=0.042850011119655536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 255: Loss=0.04287:  32%|███▏      | 254/782 [03:33<06:39,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2600: Loss=0.04181300541933845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 355: Loss=0.04912:  45%|████▌     | 354/782 [04:59<05:25,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2700: Loss=0.04168848408495679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 455: Loss=0.04445:  58%|█████▊    | 454/782 [06:25<04:06,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2800: Loss=0.04175590570358669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 555: Loss=0.03779:  71%|███████   | 554/782 [07:52<03:00,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 2900: Loss=0.0418675480520024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 655: Loss=0.03786:  84%|████████▎ | 654/782 [09:17<01:35,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3000: Loss=0.04061716444352094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 755: Loss=0.03544:  96%|█████████▋| 754/782 [10:43<00:22,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3100: Loss=0.039965021186599545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3 Iter 782: Loss=0.05008: 100%|██████████| 782/782 [11:12<00:00,  1.16it/s]\n",
      "Ep 4 Iter 73: Loss=0.04584:   9%|▉         | 72/782 [00:56<09:16,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3200: Loss=0.041153512675972545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 173: Loss=0.04235:  22%|██▏       | 172/782 [02:22<08:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3300: Loss=0.0418728424199656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 273: Loss=0.04526:  35%|███▍      | 272/782 [03:48<06:35,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3400: Loss=0.039968300537735806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 373: Loss=0.03485:  48%|████▊     | 372/782 [05:15<05:21,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3500: Loss=0.03929505387649817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 473: Loss=0.04095:  60%|██████    | 472/782 [06:41<04:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3600: Loss=0.03905038294546744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 573: Loss=0.03558:  73%|███████▎  | 572/782 [08:07<02:42,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3700: Loss=0.038952243605665134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 673: Loss=0.04026:  86%|████████▌ | 672/782 [09:33<01:27,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3800: Loss=0.03860693790164648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 773: Loss=0.03741:  99%|█████████▊| 772/782 [11:00<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss @ iteration 3900: Loss=0.040014855490595684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4 Iter 782: Loss=0.03913: 100%|█████████▉| 781/782 [11:15<00:00,  1.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
